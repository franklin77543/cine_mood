# CineMood 硬體需求評估

## 專案硬體需求

### 最低配置
- **CPU**: 4核心處理器
- **RAM**: 16GB
- **GPU**: 非必須（CPU 模式可運行）
- **儲存**: 20GB 可用空間
- **作業系統**: Windows 10/11, macOS, Linux

### 建議配置
- **CPU**: 8核心以上處理器
- **RAM**: 32GB
- **GPU**: 8GB VRAM（NVIDIA/AMD）
- **儲存**: 50GB SSD
- **作業系統**: Windows 11, Linux

---

## 目標機器評估：HP OMEN Gaming Laptop 16-AM0269T

### 硬體規格

#### ✅ CPU: Intel Core i7-14650HX
- **核心數**: 16核心 / 24執行緒
- **基本時脈**: 2.20 GHz
- **快取**: L1 1.4MB / L2 24MB / L3 30MB
- **評估**: **優秀** - 遠超需求，足以並行處理 FastAPI、Ollama LLM 和其他服務

#### ✅ RAM: 32GB DDR5
- **容量**: 32GB
- **速度**: 5600 MT/s
- **類型**: SODIMM (2x16GB)
- **評估**: **優秀** - 超過建議配置
  - Llama3.1:8b 模型: ~5-6GB
  - ChromaDB 向量資料庫: ~2-3GB
  - FastAPI + 應用程式: ~2-4GB
  - 系統 + Chrome: ~4-6GB
  - **剩餘空間**: 充足，可同時運行多個服務

#### ✅ GPU 0: NVIDIA GeForce RTX 5070 Laptop
- **VRAM**: 8GB 專屬記憶體
- **共用記憶體**: 15.8GB
- **總記憶體**: 23.8GB
- **DirectX**: 12 (FL 12.1)
- **評估**: **優秀** - 可大幅加速 AI 運算
  - Ollama LLM 推理速度提升 5-10 倍
  - Sentence Transformers 向量化加速
  - 支援 CUDA，與 PyTorch/TensorFlow 完美整合

#### ✅ GPU 1: Intel UHD Graphics (整合顯卡)
- **評估**: 可作為備用或多顯示器輸出

#### ✅ 儲存空間：雙 SSD 配置

**SSD 0 (C:) - Samsung MZVL81T0HFLB**
- **容量**: 954GB (1TB NVMe)
- **類型**: 系統碟
- **評估**: **優秀** - 高效能 Samsung NVMe SSD

**SSD 1 (D:) - Kingston SNV3S1000G**
- **容量**: 932GB (1TB NVMe)
- **類型**: 資料碟
- **評估**: **優秀** - 額外獨立儲存空間

**總容量**: 約 1.9TB
- **評估**: **遠超需求** - 儲存空間非常充足

**建議配置**:
- **C: 系統碟**:
  - 作業系統與系統軟體: ~150GB
  - 開發工具 (VS Code, Python, Node.js): ~20GB
  - 其他應用程式: ~100GB
  - **剩餘**: 600GB+
  
- **D: 專案資料碟** (建議):
  - CineMood 專案程式碼: ~1GB
  - Ollama 模型 (Llama3.1:8b): ~5-10GB
  - 電影資料庫 (SQLite): ~5-20GB
  - ChromaDB 向量資料庫: ~2-5GB
  - TMDB 下載資料: ~10-30GB
  - 開發環境與依賴: ~5-10GB
  - **預估總用量**: 30-80GB
  - **剩餘**: 850GB+ 供未來擴展

---

## 效能預估

### LLM 推理效能（使用 RTX 5070）
- **Llama3.1:8b 推理速度**: 20-50 tokens/秒
- **意圖解析延遲**: 0.5-2秒
- **推薦理由生成**: 1-3秒
- **並發能力**: 可同時處理 2-3 個請求

### 資料庫查詢效能
- **SQLite 精確搜尋**: < 50ms
- **ChromaDB 向量搜尋**: 50-200ms（取決於資料量）
- **總 API 回應時間**: 目標 < 2秒 ✅ **可達成**

### 系統整體效能
- **冷啟動時間**: 5-15秒（載入模型）
- **熱請求回應**: < 2秒
- **記憶體使用**: 預估 12-18GB（含模型）
- **CPU 使用率**: 平均 10-30%（推理時可達 60-80%）
- **GPU 使用率**: 推理時 30-70%

---

## 開發環境建議

### 軟體環境
1. **作業系統**: Windows 11（當前）
2. **Python**: 3.13+
3. **Node.js**: 20+ LTS（前端開發）
4. **Ollama**: 最新版本
5. **Docker**: 可選（用於容器化部署）

### GPU 驅動
- **NVIDIA 驅動**: 32.0.15.7703（已安裝）
- **CUDA Toolkit**: 建議安裝 12.x 版本
- **cuDNN**: 搭配 CUDA 安裝

### 開發工具
- **IDE**: VS Code / PyCharm
- **API 測試**: Postman / Thunder Client
- **資料庫管理**: DB Browser for SQLite
- **Git**: 版本控制

---

## 潛在瓶頸與優化建議

### 可能的瓶頸
1. **LLM 首次推理**: 模型載入需要 5-15 秒
   - **解決方案**: 應用程式啟動時預載入模型
   
2. **大量並發請求**: GPU 記憶體可能不足
   - **解決方案**: 實作請求佇列和限流機制
   
3. **向量資料庫規模**: 超過 10 萬部電影時可能變慢
   - **解決方案**: 使用分層索引或 HNSW 演算法

### 優化建議
1. **使用 GPU 加速**: 確保 Ollama 使用 CUDA
2. **啟用模型量化**: 可選 4-bit 量化節省記憶體
3. **快取熱門查詢**: 使用 `functools.lru_cache`
4. **批次處理**: 向量化時批次處理可提升效能
5. **SSD 優化**: 確保資料庫存放在 SSD 上

---

## 結論

### ✅ 硬體適配性評估：**完全合格**

HP OMEN Gaming Laptop 16-AM0269T 的配置**遠超**CineMood 專案需求：

1. ✅ **CPU 效能**: 16核心足以應付所有計算需求
2. ✅ **記憶體容量**: 32GB 非常充裕
3. ✅ **GPU 加速**: RTX 5070 可大幅提升 AI 推理速度
4. ✅ **多工能力**: 可同時運行開發環境、前端、後端、資料庫和 AI 模型
5. ✅ **擴充性**: 有足夠餘裕應對未來功能擴展

### 預期開發體驗
- **編譯速度**: 快速
- **熱重載**: 流暢
- **模型推理**: 即時回應
- **整體開發**: 非常順暢，無需擔心效能問題

### 建議行動
1. 確認 SSD 容量充足（建議 512GB+）
2. 安裝 CUDA Toolkit 以啟用 GPU 加速
3. 配置 Ollama 使用 NVIDIA GPU
4. 開始開發，硬體完全沒問題！

---

**評估日期**: 2025-11-18  
**評估版本**: 1.0  
**評估人員**: GitHub Copilot
